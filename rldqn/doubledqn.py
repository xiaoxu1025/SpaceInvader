# -*- coding: utf-8 -*-
"""
@Time ï¼š 2021/7/13 ä¸Šåˆ9:13
@Auth ï¼š leex-1312759081@qq.com
@File ï¼šdoubledqn.py
@IDE ï¼šPyCharm
@Mottoï¼šæ¢¦ä¸­æ¢¦è§æ¢¦ä¸­äºº

"""

# double dqn implement
# double dqn  å’Œ nature dqn ä»…ä»…åœ¨update_modelæ–¹æ³•é‡Œæœ‰åŒºåˆ«
# nature dqn æ˜¯ä» ğ‘„â€² å– q å€¼æœ€å¤§çš„ action
# double dqn 1 è€Œæ˜¯å…ˆåœ¨å½“å‰Qç½‘ç»œä¸­å…ˆæ‰¾å‡ºæœ€å¤§Qå€¼å¯¹åº”çš„åŠ¨ä½œ 2 ç„¶ååˆ©ç”¨è¿™ä¸ªé€‰æ‹©å‡ºæ¥çš„åŠ¨ä½œåœ¨ç›®æ ‡ç½‘ç»œé‡Œé¢å»è®¡ç®—ç›®æ ‡Qå€¼
from rldqn.naturedqn import NatureDQN
import numpy as np
from keras.utils import to_categorical


class DoubleDQN(NatureDQN):

    def __init__(self, model, policies, q_values_func, memory, preprocessor, batch_size,
                 target_update_freq, gamma):
        super(DoubleDQN, self).__init__(model, policies, q_values_func, memory, preprocessor, batch_size,
                                        target_update_freq, gamma)

    def update_model(self, update_nums):
        states, actions, rewards, next_states, is_ends = self.memory.sample(self.batch_size)
        states_normal, actions_normal, next_states_normal = self.preprocessor.get_batch_data(states, actions,
                                                                                             next_states)
        # 1 å…ˆåœ¨å½“å‰Qç½‘ç»œä¸­å…ˆæ‰¾å‡ºæœ€å¤§Qå€¼å¯¹åº”çš„åŠ¨ä½œ
        q_values = self.calc_q_values_func(next_states_normal)
        q_values_actions = np.argmax(q_values, axis=1)

        q_values_actions = to_categorical(q_values_actions, self.preprocessor.action_nums)
        # 2 ç„¶ååˆ©ç”¨è¿™ä¸ªé€‰æ‹©å‡ºæ¥çš„åŠ¨ä½œåœ¨ç›®æ ‡ç½‘ç»œé‡Œé¢å»è®¡ç®—ç›®æ ‡Qå€¼
        target_q_values = self.target_model.predict_on_batch([next_states_normal, q_values_actions])

        new_rewards = rewards + self.gamma * target_q_values

        y = np.where(is_ends, rewards, new_rewards)
        y = np.expand_dims(y, axis=1)

        loss = self.model.train_on_batch([states, actions_normal], y)

        print('%s update model train loss: %s ' % (update_nums, loss))

        if self.step_nums != 0 and self.step_nums % self.target_update_freq == 0:
            print("update target model %s steps and %s times" % (
                self.step_nums, self.step_nums // self.target_update_freq))
            self.update_target_model_weights()
